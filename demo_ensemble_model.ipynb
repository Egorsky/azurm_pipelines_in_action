{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Azure pipelines in action\n",
    "\n",
    "This Jupyter Notebook contains pipeline for the ensemble model. The data for the pipeline is synthetic.\n",
    "\n",
    "Pipelines is difficult to master at once but following instruction from this notebooks with the deployment of the ensemble model pipeline you will be able to deploy one with any level of difficulty. \n",
    "\n",
    "The pipeline itself contains of components. Components are pieces of code, meaning the a pipeline is a sequence of pieces of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1699969064638
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1699969065496
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace_name = \"<WORKSPACE_NAME>\"\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1699969066114
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# authenticate\n",
    "credential = DefaultAzureCredential()\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "As it mentioned in the documentation `MLClient` is \"lazy\" meaning it should be woken up in order to start registering anything. Therefore we're loading dataset to activate the client. This  happens because the client creation of the client itself doesn't assign it to the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1699969066404
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "credit_data = ml_client.data.get(name=\"test-data\", version=\"1\")\n",
    "print(f\"Data asset URI: {credit_data.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1699969066761
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Setting up environment\n",
    "\n",
    "The environment should not only contain necessary packages for working with data and models that we are planing to use. It should also have packages for the access to the secrets so we should be able to use those without direct exposing in the notebook or in the `.py` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dependencies/conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/conda.yaml\n",
    "name: conda_env\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - pip=20.0\n",
    "  - pip:\n",
    "    - azureml-mlflow==1.50.0\n",
    "    - azure-ai-ml == 1.11.1\n",
    "    - tensorflow==2.7.0\n",
    "    - numpy==1.21.4\n",
    "    - scikit-learn==1.0.1\n",
    "    - pandas==1.5.3\n",
    "    - matplotlib==3.2.2\n",
    "    - protobuf==3.20.0\n",
    "    - mldesigner==0.1.0b12\n",
    "    - prophet==1.1.4\n",
    "    - seaborn==0.12.2\n",
    "    - sklearn-pandas==1.7.0\n",
    "    - statsmodels\n",
    "    - openpyxl==3.1.2\n",
    "    - xlsxwriter==3.1.5 \n",
    "    - azure-keyvault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Setting Up Compute\n",
    "\n",
    "The next crucial step is to configure your compute environment. The choice of compute resources should align with the complexity and requirements of your task. In this example, we are using the default compute with a low-priority tier.\n",
    "\n",
    "**Note:** If you want your compute to access secrets from `Key Vault`, you need to add a Managed Identity to it and assign it as a System Managed Identity. This can be done from within the Compute tab. It's an essential step if you want your compute cluster to have access to SAS tokens. This becomes particularly important when dealing with private containers, and you wish to avoid exposing tokens within your notebook.\n",
    "\n",
    "An alternative approach is to set up an entity with System Managed Identity and assign all computes to it. Both solutions have their pros and cons, and the final decision depends on the architecture and security restrictions. We will discuss these considerations further in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1699969067863
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named cluster-demo, we'll reuse it as is.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Name assigned to the compute cluster\n",
    "cpu_compute_target = \"cluster-demo\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(\n",
    "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "\n",
    "    # Let's create the Azure Machine Learning compute object with the intended parameters\n",
    "    cpu_cluster = AmlCompute(\n",
    "        name=cpu_compute_target,\n",
    "        # Azure Machine Learning Compute is the on-demand VM service\n",
    "        type=\"amlcompute\",\n",
    "        # VM Family\n",
    "        size=\"STANDARD_DS3_V2\",\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in cluster\n",
    "        max_instances=2,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=180,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"LowPriority\",\n",
    "    )\n",
    "    print(\n",
    "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
    "    )\n",
    "    # Now, we pass the object to MLClient's create_or_update method\n",
    "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1699969068668
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name aml-dss-test is registered to workspace, the environment version is 0.0.2\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"aml-dss-test\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for Customer Complients Forecasting pipeline\",\n",
    "    tags={\"purpose\": \"demo\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.0.2\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Sales Forecasting\n",
    "\n",
    "In this section components which are used to forecast sales are presented. This part of the pipeline consists of model training and forecasting which comes separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sales Forecasting with SARIMA Model\n",
    "\n",
    "This component predicts future sales using a Seasonal Autoregressive Integrated Moving Average (SARIMA) model. It leverages historical sales data to make accurate forecasts.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "1. **Data Retrieval**: Accesses sales data stored in Azure Blob Storage using a secure SAS token.\n",
    "\n",
    "2. **Data Splitting**: Divides the sales data into training, testing, and validation sets for model training and evaluation.\n",
    "\n",
    "3. **Model Training**: Utilizes a SARIMA model to learn patterns from historical sales data, helping to make future predictions.\n",
    "\n",
    "4. **Testing and Validation**: Assesses the model's accuracy by testing it on a subset of data and validating it on another. This ensures the model's robustness.\n",
    "\n",
    "5. **Logging Metrics**: Records essential metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and more.\n",
    "\n",
    "6. **Logging Plots**: Captures visual representations of predicted sales against actual sales, aiding in understanding model performance.\n",
    "\n",
    "7. **Saving Model**: Persists the trained SARIMA model for future use.\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. **Configuration**: Set parameters like SAS token and model orders for optimal results.\n",
    "\n",
    "2. **Data Access**: Fetches historical sales data securely from Azure Blob Storage.\n",
    "\n",
    "3. **Model Training**: Learns patterns from historical data to make accurate future sales predictions.\n",
    "\n",
    "4. **Evaluation**: Assesses model accuracy through testing and validation, providing insights into its performance.\n",
    "\n",
    "5. **Metric Logging**: Records key metrics to measure the effectiveness of the model.\n",
    "\n",
    "6. **Plot Logging**: Visualizes predictions and actual sales through plots for a better understanding.\n",
    "\n",
    "7. **Model Persistence**: Saves the trained SARIMA model for later use in forecasting.\n",
    "\n",
    "Make sure to have necessary libraries and dependencies installed before running the component.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Note:** You may observe that we are utilizing `secret_client` to access the SAS token. This is achieved by assigning a `System Managed Identity` to the compute cluster. After completing this stage, it is crucial to grant your cluster access to the `Secrets`. To do this, navigate to the `Key Vault` dedicated to your subscription in the Azure Portal. In the `Access Policies` section, create access to the Secrets. When granting access to the secrets, locate your compute in the search bar of the subsequent window by typing `<YOUR_AZUREML_RESOURCE_NAME>/computes/<NAME_OF_THE_VIRTUAL_MACHINE_OR_CLUSTER>`. Once this is done, for the `client_id`, you need to find your compute in the `Active Directory` and copy the `Application ID` of your compute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1699969068963
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sarima_train_src_dir = \"./components/demo_sales_model_training\"\n",
    "os.makedirs(sarima_train_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/demo_sales_model_training/demo_model_training_sales.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {sarima_train_src_dir}/demo_model_training_sales.py\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from mldesigner import command_component, Input, Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import argparse\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import ManagedIdentityCredential\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "\n",
    "def select_first_file(path):\n",
    "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
    "    Args:\n",
    "        path (str): path to directory or file to choose\n",
    "    Returns:\n",
    "        str: full path of selected file\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "\n",
    "def read_data(sas_token, secret_client):\n",
    "\n",
    "    data_container_link = \"<CONTAINER_URL>\"\n",
    "    filename = '/sales_complaints_synthetic.csv'\n",
    "    sas_token = secret_client.get_secret(name=sas_token).value\n",
    "\n",
    "    data_asset_url_with_sas = f\"{data_container_link}{filename}?{sas_token}\" \n",
    "    df = pd.read_csv(data_asset_url_with_sas)\n",
    "    df['Calendar day'] = pd.to_datetime(df['Calendar day'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "def model_train_sales(X_train, order: tuple, seasonal_order: tuple):\n",
    "\n",
    "    model = sm.tsa.SARIMAX(X_train['sales'], order=order, seasonal_order=seasonal_order)\n",
    "    results = model.fit()\n",
    "\n",
    "    mlflow.statsmodels.log_model(results, artifact_path=\"sarima_model\")\n",
    "\n",
    "    return model, results\n",
    "\n",
    "def data_split(df):\n",
    "\n",
    "    # Splitting data. This can be wrapped into function  \n",
    "    df_70 = round(len(df) * 0.7)\n",
    "    remaining_rows = len(df) - df_70\n",
    "\n",
    "    if remaining_rows % 2 != 0:\n",
    "        df_15 = (remaining_rows // 2) + 1\n",
    "    else:\n",
    "        df_15 = remaining_rows // 2\n",
    "\n",
    "    mlflow.log_metric(\"70% of the original dataframe\", df_70)\n",
    "    mlflow.log_metric(\"15% of the original dataframe\", df_15)\n",
    "\n",
    "    X_train = df.iloc[:df_70, :]  \n",
    "    X_test = df.iloc[df_70:df_70 + df_15, :]  \n",
    "    X_val = df.iloc[df_70 + df_15:, :]\n",
    "\n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def model_test(y_test, results):\n",
    "\n",
    "    test  = results.get_prediction(start=y_test.index[0], end=y_test.index[-1])\n",
    "    y_pred = test.predicted_mean\n",
    "    test_confidence_intervals = test.conf_int(alpha=0.2)\n",
    "\n",
    "    return y_pred, test_confidence_intervals\n",
    "\n",
    "def model_val(y_val, results):\n",
    "    forecast = results.get_forecast(steps=len(y_val))\n",
    "    y_val_pred = forecast.predicted_mean\n",
    "    forecast_confidence_intervals = forecast.conf_int(alpha=0.2)\n",
    "\n",
    "    return y_val_pred, forecast_confidence_intervals\n",
    "\n",
    "def log_metrics(y_test, y_pred, test: bool):\n",
    "       \n",
    "    def calculate_rmse(predictions, targets):\n",
    "        return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "    \n",
    "    \n",
    "    mse = mean_squared_error(y_true=y_test,\n",
    "                                y_pred=y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test,\n",
    "                                        y_pred=y_pred))\n",
    "    mae = mean_absolute_error(y_true=y_test,\n",
    "                                y_pred=y_pred)\n",
    "\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "    \n",
    "        # Check for input shape compatibility\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError(f\"Input shapes do not match ({y_true.shape}), ({y_pred.shape})\")\n",
    "    \n",
    "        # Calculate absolute percentage error\n",
    "        absolute_error = np.abs((y_true - y_pred) / y_true)\n",
    "    \n",
    "        # Replace infinite values with zero and ignore NaN values\n",
    "        absolute_error = np.nan_to_num(absolute_error, nan=0, posinf=0, neginf=0)\n",
    "    \n",
    "        # Calculate the mean of absolute percentage error\n",
    "        mape = np.mean(absolute_error) * 100\n",
    "    \n",
    "        return mape\n",
    "    \n",
    "    mape = mean_absolute_percentage_error(y_true=y_test, \n",
    "                                            y_pred=y_pred)\n",
    "    smape = np.mean(\n",
    "        2 * np.abs(y_test.values - y_pred) / (np.abs(y_test.values) + np.abs(y_pred))\n",
    "        ) * 100\n",
    "\n",
    "    rmse_seasonal = calculate_rmse(y_pred, y_test.values)\n",
    "\n",
    "    nrmse_seasonal = rmse_seasonal / (np.max(y_test.values) - np.min(y_test.values))\n",
    "\n",
    "    if test:\n",
    "\n",
    "        # Logging all metrics\n",
    "        mlflow.log_metric('Sales MAE', mae)\n",
    "        mlflow.log_metric('Sales MSE', mse)\n",
    "        mlflow.log_metric('Sales RMSE', rmse)\n",
    "        mlflow.log_metric('Sales MAPE', mape)\n",
    "        mlflow.log_metric('Sales NRMSE', nrmse_seasonal)\n",
    "        \n",
    "    else:\n",
    "        # Logging all metrics\n",
    "        mlflow.log_metric('Sales Validation MAE', mae)\n",
    "        mlflow.log_metric('Sales Validation MSE', mse)\n",
    "        mlflow.log_metric('Sales Validation RMSE', rmse)\n",
    "        mlflow.log_metric('SalesValidation MAPE', mape)\n",
    "        mlflow.log_metric('Sales Validation NRMSE', nrmse_seasonal)\n",
    "\n",
    "def log_plots(y_test, forecasted_values, confidence_intervals, axis, name):\n",
    "\n",
    "    # Plot the actual and predicted values\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Plot the data\n",
    "    ax.plot(axis['Calendar day'], forecasted_values, label='prediction')\n",
    "    ax.plot(axis['Calendar day'], y_test, label='Actual')\n",
    "    ax.set_title(str(name) + \" plot for complaints\")\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Complaints')\n",
    "    ax.legend()\n",
    "\n",
    "    # Fill the confidence intervals\n",
    "    ax.fill_between(axis['Calendar day'], confidence_intervals['lower sales'], confidence_intervals['upper sales'],\n",
    "                    color='gray', alpha=0.3, label='Confidence Intervals')\n",
    "    \n",
    "    mlflow.log_figure(fig,str(name) + 'plot.png')\n",
    "\n",
    "def main():\n",
    "\n",
    "    \"\"\"Main function of the script\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sas token\n",
    "    parser.add_argument(\"--sas_token\", type=str)\n",
    "\n",
    "    # Features arguments\n",
    "    parser.add_argument(\"--p_input\", type=int)\n",
    "    parser.add_argument(\"--d_input\", type=int)\n",
    "    parser.add_argument(\"--q_input\", type=int)\n",
    "    parser.add_argument(\"--p_seasonal_input\", type=int)\n",
    "    parser.add_argument(\"--d_seasonal_input\", type=int)\n",
    "    parser.add_argument(\"--q_seasonal_input\", type=int)\n",
    "    parser.add_argument(\"--s_input\", type=int)\n",
    "\n",
    "    # Output dataframe\n",
    "    parser.add_argument(\"--df_original\", type=str, help=\"path to the file df_original.csv\")\n",
    "    parser.add_argument(\"--training_data_sales\", type=str, help=\"path to the file X_train_original.csv\")\n",
    "    parser.add_argument(\"--testing_data_sales\",type=str, help=\"path to the file X_test_original.csv\")\n",
    "    parser.add_argument(\"--validation_data_sales\", type=str, help=\"path to the file X_val_original.csv\")\n",
    "    parser.add_argument(\"--model\",type=str, help=\"path to the model file\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    credential = ManagedIdentityCredential(client_id = open('client_id.txt').readline())  # Client id is an Application ID from Active Directory (Entra ID). It is hidden in .txt for security purposes.\n",
    "    secret_client = SecretClient(vault_url='<KEY_VAULT_URL>', credential=credential)  # Secret Client initialization with th access to the desired Key Valut\n",
    "\n",
    "    # Reading data\n",
    "    df = read_data(args.sas_token, secret_client=secret_client)\n",
    "\n",
    "    # Splitting data\n",
    "    X_train, X_test, X_val = data_split(df)\n",
    "    print(len(X_train),len(X_test),len(X_val))\n",
    "\n",
    "    print(X_train.head())\n",
    "\n",
    "    # Saving data in order not to access the blob several time and just pass it to the other component\n",
    "    df.to_csv(Path(args.df_original) /  \"df_original.csv\")\n",
    "    X_train.to_csv(Path(args.training_data_sales) /  \"X_train_original.csv\")\n",
    "    X_test.to_csv(Path(args.testing_data_sales) /  \"X_test_original.csv\")\n",
    "    X_val.to_csv(Path(args.validation_data_sales) /  \"X_val_original.csv\")\n",
    "\n",
    "\n",
    "    # Specify the SARIMA orders: (p, d, q) for non-seasonal, (P, D, Q, S) for seasonal\n",
    "    order = (args.p_input, args.d_input, args.q_input)\n",
    "    seasonal_order = (args.p_seasonal_input, args.d_seasonal_input, args.q_seasonal_input, args.s_input)\n",
    "\n",
    "    # Model fitting\n",
    "    model, results = model_train_sales(X_train[['Calendar day', 'sales']], order=order, seasonal_order=seasonal_order)\n",
    "\n",
    "    results.summary()\n",
    "\n",
    "    # Test the model\n",
    "    y_pred, test_confidence_intervals = model_test(X_test[['Calendar day', 'sales']], results)\n",
    "\n",
    "    # Model validation\n",
    "    y_val_pred, val_confidence_intervals = model_val(X_val[['Calendar day', 'sales']], results)\n",
    "\n",
    "    # Logging metrics for testing and then for validation\n",
    "    log_metrics(X_test['sales'], y_pred, test=True)\n",
    "    log_metrics(X_val['sales'], y_val_pred, test=False)\n",
    "\n",
    "    # Logging plots\n",
    "    log_plots(y_test=X_test['sales'], \n",
    "              forecasted_values=y_pred, \n",
    "              confidence_intervals=test_confidence_intervals, \n",
    "              axis=X_test, \n",
    "              name=\"Test\")\n",
    "    log_plots(y_test=X_val['sales'], \n",
    "              forevasted_values=y_val_pred, \n",
    "              confidence_intervals=val_confidence_intervals, \n",
    "              axis=X_val, \n",
    "              name=\"Validation\")\n",
    "\n",
    "    # Saving the model\n",
    "    model_filename =  os.path.join(args.model,f'sarima_model_sales.pkl')\n",
    "    pickle.dump(results, open(model_filename, 'wb'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1699969069520
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "demo_sales_model_training_component = command(\n",
    "    name=\"demo_sales_model_training\",\n",
    "    display_name=\"Model training for sales forecasting\",\n",
    "    description=\"Reads data, plit it into train, test and validation. Then model is created. The model is tested on test and validation datasets\",\n",
    "    inputs={\n",
    "        \"sas_token\": Input(type=\"string\"),\n",
    "        \"p_input\": Input(type=\"integer\", default=1),\n",
    "        \"d_input\": Input(type=\"integer\", default=0),\n",
    "        \"q_input\": Input(type=\"integer\", default=1),\n",
    "        \"p_seasonal_input\": Input(type=\"integer\", default=3),\n",
    "        \"d_seasonal_input\": Input(type=\"integer\", default=0),\n",
    "        \"q_seasonal_input\": Input(type=\"integer\", default=3),\n",
    "        \"s_input\": Input(type=\"integer\", default=12),\n",
    "    },\n",
    "    outputs=dict(\n",
    "        model=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        df_original=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        training_data_sales=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        testing_data_sales=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        validation_data_sales=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    ),\n",
    "    code=sarima_train_src_dir,\n",
    "    command=\"\"\"python demo_model_training_sales.py \\\n",
    "            --sas_token ${{inputs.sas_token}} --p_input ${{inputs.p_input}} \\\n",
    "            --d_input ${{inputs.d_input}} --q_input ${{inputs.q_input}} \\\n",
    "            --p_seasonal_input ${{inputs.p_seasonal_input}} --d_seasonal_input ${{inputs.d_seasonal_input}} \\\n",
    "            --q_seasonal_input ${{inputs.q_seasonal_input}} --s_input ${{inputs.s_input}} \\\n",
    "            --model ${{outputs.model}} --df_original ${{outputs.df_original}} \\\n",
    "            --training_data_sales  ${{outputs.training_data_sales}} --testing_data_sales ${{outputs.testing_data_sales}} \\\n",
    "            --validation_data_sales ${{outputs.validation_data_sales}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1699969071643
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component demo_sales_model_training with Version 2023-11-14-13-37-50-4370446 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "demo_sales_model_training_component = ml_client.create_or_update(\n",
    "    demo_sales_model_training_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {demo_sales_model_training_component.name} with Version {demo_sales_model_training_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Sales forecasting component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1699969071756
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sarima_forecast_src_dir = \"./components/demo_sarima_forecast\"\n",
    "os.makedirs(sarima_forecast_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/demo_sarima_forecast/demo_sarima_forecast_sales.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {sarima_forecast_src_dir}/demo_sarima_forecast_sales.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from mldesigner import command_component, Input, Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import argparse\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "def select_first_file(path):\n",
    "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
    "    Args:\n",
    "        path (str): path to directory or file to choose\n",
    "    Returns:\n",
    "        str: full path of selected file\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "\n",
    "def sarima_model_forecast(X_val, results, out_of_sample_forecast_days=60):\n",
    "\n",
    "    X_val['Calendar day'] = pd.to_datetime(X_val['Calendar day'])\n",
    "    \n",
    "    \n",
    "    forecast_date_rng = pd.date_range(start=X_val['Calendar day'].iloc[-1] + pd.Timedelta(days=1), \n",
    "                                        periods=out_of_sample_forecast_days,\n",
    "                                        freq=\"D\"\n",
    "                                        )\n",
    "\n",
    "    forecast = results.get_forecast(steps=out_of_sample_forecast_days)\n",
    "\n",
    "    # Extract the forecasted values and confidence intervals\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    forecast_confidence_intervals = forecast.conf_int(alpha=0.2)\n",
    "\n",
    "    forecast_df = pd.DataFrame({'Calendar day': forecast_date_rng, 'sales': forecast_values})\n",
    "\n",
    "    forecast_df.set_index('Calendar day', inplace=True, drop=False)\n",
    "    forecast_df.rename_axis(None, inplace=True)\n",
    "\n",
    "    return forecast_values, forecast_confidence_intervals, forecast_df, forecast_date_rng\n",
    "\n",
    "def log_plots(X_val, forecast_date_rng, forecast_values, forecast_confidence_intervals, name):\n",
    "\n",
    "    # Plot the actual and predicted values\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    plt.plot(X_val['Calendar day'], X_val['sales'], label='Observed')\n",
    "    plt.plot(forecast_date_rng, forecast_values, label='Forecast', color='red')\n",
    "    plt.fill_between(\n",
    "        forecast_date_rng,\n",
    "        forecast_confidence_intervals['lower sales'],\n",
    "        forecast_confidence_intervals['upper sales'],\n",
    "        color='pink',\n",
    "        alpha=0.3,\n",
    "        )\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.grid(visible=True)\n",
    "    plt.legend()\n",
    "\n",
    "    mlflow.log_figure(fig,str(name) + 'plot.png')\n",
    "\n",
    "def main():\n",
    "    \"Main function of the script\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_forecast\", type=str, help='path to the file')\n",
    "    parser.add_argument(\"--df\", type=str, help='path to the file')\n",
    "    parser.add_argument(\"--X_val\", type=str, help='path ot the file')\n",
    "    parser.add_argument(\"--df_extended\", type=str, help=\"path to the file\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load model\n",
    "    files = [f for f in os.listdir(args.model_forecast) if f.endswith(\".pkl\")]\n",
    "    model = joblib.load(args.model_forecast + \"/\" + files[0])\n",
    "    print(model.summary())\n",
    "\n",
    "    # Reading data from previous step\n",
    "    df = pd.read_csv(select_first_file(args.df))\n",
    "    X_val = pd.read_csv(select_first_file(args.X_val))\n",
    "\n",
    "    # Making forecast\n",
    "    forecast_values, forecast_confidence_intervals, forecast_df, forecast_date_rng = sarima_model_forecast(X_val, model)\n",
    "\n",
    "    df_extended = pd.concat([df, forecast_df], ignore_index=True)\n",
    "    df_extended.complaints.fillna(0.0, inplace=True)\n",
    "    df_extended.to_csv((Path(args.df_extended) / 'df_extended.csv'))\n",
    "\n",
    "    log_plots(X_val, forecast_date_rng, forecast_values, forecast_confidence_intervals, 'Sales Forecast ')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1699969071965
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "demo_sales_forecast_component = command(\n",
    "    name=\"demo_sales_forecast\",\n",
    "    display_name=\"Demo Sales Forecast\",\n",
    "    description=\"This component utilizes SARIMA model to make out of sample forecast. The foracst get concatinated with the original DataFrame\",\n",
    "    inputs={\n",
    "        \"model_forecast\": Input(type=\"uri_folder\"),\n",
    "        \"df\": Input(type=\"uri_folder\"),\n",
    "        \"X_val\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs=dict(df_extended=Output(type=\"uri_folder\", mode=\"rw_mount\")),\n",
    "    code=sarima_forecast_src_dir,\n",
    "    command=\"\"\"python demo_sarima_forecast_sales.py \\\n",
    "              --df ${{inputs.df}} --model_forecast ${{inputs.model_forecast}} \\\n",
    "              --X_val ${{inputs.X_val}} --df_extended ${{outputs.df_extended}} \\\n",
    "              \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1699969073200
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component demo_sales_forecast with Version 2023-11-14-13-37-52-6875169 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "demo_sales_forecast_component = ml_client.create_or_update(\n",
    "    demo_sales_forecast_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {demo_sales_forecast_component.name} with Version {demo_sales_forecast_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Complaints forecasting\n",
    "\n",
    "This section is dedicated to the complaints forecasting components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Feature Creation\n",
    "\n",
    "This component enhances sales data by creating additional features for better predictive modeling. It introduces lagged values and a moving average to capture temporal patterns in the data.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "1. **Data Loading**: Retrieves sales data from the previous step for feature creation.\n",
    "\n",
    "2. **Lagged Values**: Creates lagged versions of a specified column to incorporate historical values as features. The number of lagged values is determined by the `num_lags` parameter.\n",
    "\n",
    "3. **Moving Average**: Generates a moving average of sales data to smooth out short-term fluctuations and highlight long-term trends. The `min_periods` parameter controls the minimum number of periods required to compute the average.\n",
    "\n",
    "4. **Output**: Saves the enhanced features, including lagged values and the moving average, to a new CSV file (`df_features.csv`).\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. **Input Data**: Provide the path to the sales data (`--df`) from the previous step.\n",
    "\n",
    "2. **Feature Configuration**: Adjust parameters such as the number of lagged values (`--num_lags`), the target column (`--column`), and the minimum periods for the moving average (`--min_periods`).\n",
    "\n",
    "3. **Feature Creation**: Generates lagged values and a moving average based on the specified parameters.\n",
    "\n",
    "4. **Output**: Saves the newly created features to a CSV file (`df_features.csv`) for further use in the pipeline.\n",
    "\n",
    "Ensure necessary libraries and dependencies are installed before running the component.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1699969073374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "feature_creation_src_dir = \"./components/demo_feature_creation\"\n",
    "os.makedirs(feature_creation_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/demo_feature_creation/demo_feature_creation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {feature_creation_src_dir}/demo_feature_creation.py\n",
    "\n",
    "#required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from mldesigner import command_component, Input, Output\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "def select_first_file(path):\n",
    "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
    "    Args:\n",
    "        path (str): path to directory or file to choose\n",
    "    Returns:\n",
    "        str: full path of selected file\n",
    "    \"\"\"\n",
    "\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "\n",
    "def create_lags(df, column_name, num_lags=1):\n",
    "\n",
    "    for i in range(1, num_lags + 1):\n",
    "        df[f'{column_name}_lag_{i}'] = df[column_name].shift(i).fillna(0.0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_moving_avg(df, min_periods):\n",
    "\n",
    "    df['sales_ma'] = df[\"sales\"].rolling(window=7, min_periods=min_periods, closed='left').mean().fillna(0.0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function of the script.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input and output parameteres\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data argument\n",
    "    parser.add_argument(\"--df\", type=str)\n",
    "\n",
    "    # Features arguments\n",
    "    parser.add_argument(\"--num_lags\", type=int)\n",
    "    parser.add_argument(\"--column\", type=str)\n",
    "    parser.add_argument(\"--min_periods\", type=int)\n",
    "\n",
    "    # Output dataframe\n",
    "    parser.add_argument(\"--df_features\",type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Calling function to read data from previous step\n",
    "    df = pd.read_csv(select_first_file(args.df))\n",
    "\n",
    "    df = create_lags(df, args.column, args.num_lags)\n",
    "\n",
    "    df_features = create_moving_avg(df, args.min_periods)\n",
    "\n",
    "    df_features.to_csv((Path(args.df_features) / 'df_features.csv'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1699969073597
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "demo_feature_creation_component = command(\n",
    "    name=\"demo_feature_creation\",\n",
    "    display_name=\"Demo feature creation for sales\",\n",
    "    description=\"This component creates lagsand moving average for the DataFrame for DSS conference.\",\n",
    "    inputs={\n",
    "        \"df\": Input(type=\"uri_folder\"),\n",
    "        \"num_lags\": Input(type=\"integer\"),\n",
    "        \"column\": Input(type=\"string\"),\n",
    "        \"min_periods\": Input(type=\"integer\"),\n",
    "    },\n",
    "    outputs=dict(df_features=Output(type=\"uri_folder\", mode=\"rw_mount\")),\n",
    "    code=feature_creation_src_dir,\n",
    "    command=\"\"\"python demo_feature_creation.py \\\n",
    "              --df ${{inputs.df}} --num_lags ${{inputs.num_lags}} \\\n",
    "              --column ${{inputs.column}} --min_periods ${{inputs.min_periods}} \\\n",
    "              --df_features ${{outputs.df_features}}\n",
    "              \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1699969074892
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component demo_feature_creation with Version 2023-11-14-13-37-54-1886876 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "demo_feature_creation_component = ml_client.create_or_update(\n",
    "    demo_feature_creation_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {demo_feature_creation_component.name} with Version {demo_feature_creation_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Complaints model component\n",
    "\n",
    "This component utilizes the Prophet model to forecast complaints based on historical data. It includes data loading, model training, testing, and validation, along with logging metrics and plots.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "1. **Data Loading**: Retrieves feature-enhanced data from the previous step for model training.\n",
    "\n",
    "2. **Model Training**: Trains a Prophet model with specified hyperparameters such as yearly seasonality, seasonality mode, changepoint scales, and more.\n",
    "\n",
    "3. **Model Forecasting**: Uses the trained model to forecast complaints for the testing data.\n",
    "\n",
    "4. **Metric Logging**: Records key metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and others for model evaluation.\n",
    "\n",
    "5. **Plot Logging**: Captures visual representations of actual vs. predicted complaints, as well as trends and components identified by the Prophet model.\n",
    "\n",
    "6. **Output**: Saves the training, testing, and validation data for future analysis.\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. **Input Data**: Provide the path to the feature-enhanced data (`--df_features`) from the previous step.\n",
    "\n",
    "2. **Model Configuration**: Adjust hyperparameters such as yearly seasonality, seasonality mode, changepoint scales, and more through command-line arguments.\n",
    "\n",
    "3. **Model Training and Forecasting**: Trains the Prophet model and uses it to forecast complaints for the testing data.\n",
    "\n",
    "4. **Metric and Plot Logging**: Captures and logs key metrics and visualizations for model evaluation.\n",
    "\n",
    "5. **Output Data**: Saves the training, testing, and validation data for future analysis.\n",
    "\n",
    "Ensure necessary libraries and dependencies are installed before running the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1699969075003
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prophet_src_dir = \"./components/demo_prophet_train\"\n",
    "os.makedirs(prophet_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/demo_prophet_train/demo_prophet_model_complaints.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {prophet_src_dir}/demo_prophet_model_complaints.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from mldesigner import command_component, Input, Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import argparse\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from prophet import Prophet\n",
    "\n",
    "def select_first_file(path):\n",
    "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
    "    Args:\n",
    "        path (str): path to directory or file to choose\n",
    "    Returns:\n",
    "        str: full path of selected file\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "\n",
    "def data_split(df):\n",
    "\n",
    "    # Splitting data. This can be wrapped into function  \n",
    "    df_70 = round(len(df) * 0.7)\n",
    "    remaining_rows = len(df) - df_70\n",
    "\n",
    "    if remaining_rows % 2 != 0:\n",
    "        df_15 = (remaining_rows // 2) + 1\n",
    "    else:\n",
    "        df_15 = remaining_rows // 2\n",
    "\n",
    "    mlflow.log_metric(\"70% of the original dataframe\", df_70)\n",
    "    mlflow.log_metric(\"15% of the original dataframe\", df_15)\n",
    "\n",
    "    X_train = df.iloc[:df_70, :]  \n",
    "    X_test = df.iloc[df_70:df_70 + df_15, :]  \n",
    "    X_val = df.iloc[df_70 + df_15:, :]\n",
    "\n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def model_train(X_train, changepoint_prior_scale, changepoint_range, seasonality_prior_scale, holidays_prior_scale, weekly_seasonality, yearly_seasonality):\n",
    "\n",
    "    model = Prophet(changepoint_prior_scale=changepoint_prior_scale, \n",
    "                    changepoint_range=changepoint_range, \n",
    "                    seasonality_prior_scale=seasonality_prior_scale, \n",
    "                    holidays_prior_scale=holidays_prior_scale, \n",
    "                    weekly_seasonality=weekly_seasonality, \n",
    "                    yearly_seasonality=yearly_seasonality)\n",
    "    \n",
    "    model.add_seasonality(period=30.4, name='monthly', fourier_order=2)\n",
    "\n",
    "    results = model.fit(X_train.rename(columns={'complaints': 'y', 'Calendar day': 'ds'}))\n",
    "    \n",
    "    global train\n",
    "    train = results.history\n",
    "\n",
    "    return model, results\n",
    "\n",
    "def model_forecast(X_test, model):\n",
    "\n",
    "    future = X_test.rename(columns={'complaints': 'y', 'Calendar day': 'ds'})\n",
    "\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    y_pred = forecast.yhat\n",
    "\n",
    "    return forecast, y_pred\n",
    "\n",
    "def log_metrics(y_test, y_pred):\n",
    "\n",
    "    def calculate_rmse(predictions, targets):\n",
    "        return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "        \n",
    "    mse = mean_squared_error(y_true=y_test,\n",
    "                                y_pred=y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test,\n",
    "                                        y_pred=y_pred))\n",
    "    mae = mean_absolute_error(y_true=y_test,\n",
    "                                y_pred=y_pred)\n",
    "\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Check for input shape compatibility\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError(f\"Input shapes do not match ({y_true.shape}), ({y_pred.shape})\")\n",
    "    \n",
    "        # Calculate absolute percentage error\n",
    "        absolute_error = np.abs((y_true - y_pred) / y_true)\n",
    "    \n",
    "        # Replace infinite values with zero and ignore NaN values\n",
    "        absolute_error = np.nan_to_num(absolute_error, nan=0, posinf=0, neginf=0)\n",
    "    \n",
    "        # Calculate the mean of absolute percentage error\n",
    "        mape = np.mean(absolute_error) * 100\n",
    "    \n",
    "        return mape\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_true=y_test, \n",
    "                                            y_pred=y_pred)\n",
    "    smape = np.mean(\n",
    "        2 * np.abs(y_test.values - y_pred) / (np.abs(y_test.values) + np.abs(y_pred))\n",
    "        ) * 100\n",
    "\n",
    "    rmse_seasonal = calculate_rmse(y_pred, y_test.values)\n",
    "\n",
    "    nrmse_seasonal = rmse_seasonal / (np.max(y_test.values) - np.min(y_test.values))\n",
    "    \n",
    "    # Logging all metrics\n",
    "    mlflow.log_metric('MAE', mae)\n",
    "    mlflow.log_metric('MSE', mse)\n",
    "    mlflow.log_metric('RMSE', rmse)\n",
    "    mlflow.log_metric('MAPE', mape)\n",
    "    mlflow.log_metric('NRMSE', nrmse_seasonal)\n",
    "\n",
    "def log_plots(y_test, y_pred, model, forecast):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    sns.set_style('whitegrid')\n",
    "    ax.plot(y_test['Calendar day'], y_test['complaints'].squeeze(), label='Actual')\n",
    "    ax.fill_between(y_test['Calendar day'], forecast['yhat_lower'], forecast['yhat_upper'], alpha=0.2)\n",
    "    plt.plot(y_test['Calendar day'], forecast['yhat'], label='Predicted')\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.grid(visible=True)\n",
    "    plt.legend()\n",
    "    mlflow.log_figure(fig, 'forecasting_result.png')\n",
    "\n",
    "    fig_m = model.plot_components(forecast)\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.legend()\n",
    "    mlflow.log_figure(fig_m, 'plot_forecasted_trends_and_components.png')\n",
    "\n",
    "  \n",
    "def main():\n",
    "    \"\"\"Main function of the script\"\"\"\n",
    "    \n",
    "    # Input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--df_features\", type=str)\n",
    "    \n",
    "    # Prophet hyperparameters. Only when default value for the variable is set int the command in the component it works, if it set here this won't be accepted as the default value.\n",
    "    parser.add_argument(\"--yearly_seasonality_input\", type=int, help=\"(Integer) Repeating patterns over year time.\", default=19)\n",
    "    parser.add_argument(\"--seasonality_mode_input\", type=str, help=\"(String) Mode of the seasonality components. Options: 'additive', 'multiplicative'\", default='multiplicative')\n",
    "    parser.add_argument(\"--changepoint_prior_scale_input\", type=float, help=\"(Float) Determines the scale of the change at thetime series trend change point.\", default=2.92877901455971)\n",
    "    parser.add_argument(\"--seasonality_prior_scale_input\", type=float, help=\"(Float) Controls themagnitude of the seasonality fluctuation.\", default=6.010013757753535)\n",
    "    parser.add_argument(\"--holidays_prior_scale_input\", type=float, help='(Float) Determines the scale of holiday effects, and is very similar to the seasonality_prior_scale.', default=4.983602164233429)\n",
    "    parser.add_argument(\"--changepoint_range_inupt\", type=float, help=\"(Float) Available between 0 and 1, indicating the percentage of historical data that allow a trend change.\", default=0.809764143539701)\n",
    "    parser.add_argument(\"--weekly_seasonality_input\", type=int, help=\"(Integer) Repeating patterns over week time.\", default=14)\n",
    "\n",
    "    # Output dataframes\n",
    "    parser.add_argument(\"--training_data\", type=str, default=\"./\", help=\"output path for training_data\")\n",
    "    parser.add_argument(\"--testing_data\", type=str, default=\"./\", help=\"output path for training_data\")\n",
    "    parser.add_argument(\"--validation_data\", type=str, help=\"output path for training_data\")\n",
    "    \n",
    "    # Model\n",
    "    parser.add_argument(\"--model_prophet\", type=str, help=\"Path to the model file.\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Reading data from previous step\n",
    "    df = pd.read_csv(select_first_file(args.df_features))\n",
    "\n",
    "    #  Splitting data into 70%  training, 15% testing and validation\n",
    "    X_train, X_test, X_val = data_split(df)\n",
    "    print(X_train.head())\n",
    "    print(X_test.head())\n",
    "    print(X_train.head())\n",
    "\n",
    "    \n",
    "    # Identifying parameter variables from the parser\n",
    "    yearly_seasonality = args.yearly_seasonality_input\n",
    "    seasonality_mode = args.seasonality_mode_input\n",
    "    changepoint_prior_scale = args.changepoint_prior_scale_input\n",
    "    seasonality_prior_scale = args.seasonality_prior_scale_input\n",
    "    holidays_prior_scale = args.holidays_prior_scale_input\n",
    "    changepoint_range = args.changepoint_range_inupt\n",
    "    weekly_seasonality = args.weekly_seasonality_input\n",
    "\n",
    "    model, results = model_train(X_train, changepoint_prior_scale=changepoint_prior_scale, changepoint_range=changepoint_range,\n",
    "                                seasonality_prior_scale=seasonality_prior_scale, holidays_prior_scale=holidays_prior_scale,\n",
    "                                weekly_seasonality=weekly_seasonality, yearly_seasonality=yearly_seasonality)\n",
    "    \n",
    "    # Registering model. This can be donein the model training function. Variable 'train' is declared as a global one.\n",
    "    signature =  infer_signature(train, results.predict(X_test.rename(columns={'complaints': 'y', 'Calendar day': 'ds'})))\n",
    "    mlflow.prophet.log_model(results, artifact_path=\"prophet_model_complaints\", signature=signature)\n",
    "\n",
    "    model_filename =  os.path.join(args.model_prophet,f'prophet_model.pkl')\n",
    "    pickle.dump(results, open(model_filename, 'wb'))\n",
    "    \n",
    "    # Testing out model on the X_test\n",
    "    forecast, y_pred = model_forecast(X_test, model)\n",
    "\n",
    "    # Logging metrics\n",
    "    log_metrics(X_test['complaints'].squeeze(), y_pred)\n",
    "\n",
    "    # Logging plots\n",
    "    log_plots(X_test, y_pred, model, forecast)\n",
    "\n",
    "    X_train.to_csv((Path(args.training_data) / \"train_data.csv\"))\n",
    "    X_test.to_csv((Path(args.testing_data) / \"test_data.csv\"))\n",
    "    X_val.to_csv((Path(args.validation_data) / \"validation_data.csv\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1699969075226
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "demo_prophet_model_complaints_component = command(\n",
    "    name=\"demo_prophet_model_complaints\",\n",
    "    display_name=\"Demo Prophet model for complaints\",\n",
    "    description=\"Component gets data with features from the feature creation component, trains and log model, metrics and plots. Splits data into train, test and validation\",\n",
    "    inputs={\n",
    "        \"df_features\": Input(type=\"uri_folder\"),\n",
    "        \"yearly_seasonality_input\": Input(type=\"integer\", default=19),\n",
    "        \"seasonality_mode_input\": Input(type=\"string\", default=\"multiplicative\"),\n",
    "        \"changepoint_prior_scale_input\": Input(type=\"number\", default=2.92877901455971),\n",
    "        \"seasonality_prior_scale_input\": Input(\n",
    "            type=\"number\", default=6.010013757753535\n",
    "        ),\n",
    "        \"holidays_prior_scale_input\": Input(type=\"number\", default=4.983602164233429),\n",
    "        \"changepoint_range_inupt\": Input(type=\"number\", default=0.809764143539701),\n",
    "        \"weekly_seasonality_input\": Input(type=\"integer\", default=14),\n",
    "    },\n",
    "    outputs=dict(\n",
    "        training_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        testing_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        validation_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        model_prophet=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    ),\n",
    "    code=prophet_src_dir,\n",
    "    command=\"\"\"python demo_prophet_model_complaints.py \\\n",
    "            --df_features ${{inputs.df_features}} --yearly_seasonality_input ${{inputs.yearly_seasonality_input}} \\\n",
    "            --seasonality_mode_input ${{inputs.seasonality_mode_input}} --changepoint_prior_scale_input ${{inputs.changepoint_prior_scale_input}} \\\n",
    "            --seasonality_prior_scale_input ${{inputs.seasonality_prior_scale_input}} --holidays_prior_scale_input ${{inputs.holidays_prior_scale_input}} \\\n",
    "            --changepoint_range_inupt ${{inputs.changepoint_range_inupt}} --weekly_seasonality_input ${{inputs.weekly_seasonality_input}} \\\n",
    "            --training_data ${{outputs.training_data}} --testing_data ${{outputs.testing_data}} --validation_data ${{outputs.validation_data}} \\\n",
    "            --model_prophet ${{outputs.model_prophet}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1699969076604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component demo_prophet_model_complaints with Version 2023-11-14-13-37-56-0108665 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "demo_prophet_model_complaints_component = ml_client.create_or_update(\n",
    "    demo_prophet_model_complaints_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {demo_prophet_model_complaints_component.name} with Version {demo_prophet_model_complaints_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Complaints forecasting component\n",
    "\n",
    "This component performs validation on the complaints forecasting model using historical data. It includes loading the training, testing, and validation datasets, making future predictions, logging metrics, and recording results to Azure Blob Storage.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "1. **Data Loading**: Retrieves training, testing, and validation datasets from the previous steps for model validation.\n",
    "\n",
    "2. **Model Validation**: Uses the trained forecasting model to make predictions for the validation dataset and assesses its performance.\n",
    "\n",
    "3. **Metric Logging**: Records key metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), etc., for model evaluation.\n",
    "\n",
    "4. **Plot Logging**: Captures visualizations of actual vs. predicted complaints and trends/components identified by the forecasting model.\n",
    "\n",
    "5. **Results Recording**: Stores the results, including future predictions, in Azure Blob Storage.\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. **Input Data**: Provide the paths to the training, testing, and validation datasets (`--training_data`, `--testing_data`, `--validation_data`) from the previous steps.\n",
    "\n",
    "2. **Azure Blob Storage Configuration**: Set the Azure Blob Storage connection string (`--conn_str`) and container name (`--container_name`) to record results.\n",
    "\n",
    "3. **Trained Model Input**: Provide the path to the directory containing the trained forecasting model (`--model`).\n",
    "\n",
    "4. **Forecasting Parameters**: Specify the forecasting parameters such as the number of periods into the future (`--periods_horizon`) and the frequency of observations (`--freq`).\n",
    "\n",
    "5. **Model Validation and Results Recording**: Validates the forecasting model on the validation dataset, logs metrics and plots, and records results to Azure Blob Storage.\n",
    "\n",
    "Ensure necessary libraries and dependencies are installed before running the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1699969076730
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "forecast_src_dir = \"./components/demo_prophet_forecast\"\n",
    "os.makedirs(forecast_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/demo_prophet_forecast/demo_complaints_forecast.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {forecast_src_dir}/demo_complaints_forecast.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from mldesigner import command_component, Input, Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet, serialize\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import ManagedIdentityCredential\n",
    "import json\n",
    "\n",
    "def select_first_file(path):\n",
    "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
    "    Args:\n",
    "        path (str): path to directory or file to choose\n",
    "    Returns:\n",
    "        str: full path of selected file\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "\n",
    "def model_validate(X_train, X_test, X_val, model, periods, freq):\n",
    "\n",
    "    future_val = X_val.rename(columns={'Calendar day': 'ds'})\n",
    "\n",
    "    forecast_val = model.predict(future_val)\n",
    "\n",
    "    forecast_val = forecast_val[-len(X_val):]\n",
    "\n",
    "    y_pred_val = forecast_val['yhat']\n",
    "\n",
    "    # Future predictions\n",
    "    last_date = forecast_val.iloc[-1]['ds']\n",
    "    last_date = last_date + datetime.timedelta(days=7)\n",
    "\n",
    "    future_dates = pd.date_range(start=last_date, periods=periods, freq=freq)\n",
    "    future_df = pd.DataFrame({'ds': future_dates})\n",
    "\n",
    "    for col in X_val.columns:\n",
    "        if col != 'ds':\n",
    "            future_df[col] = 0\n",
    "    \n",
    "    # Drop the first row    \n",
    "    future_predictions = model.predict(future_df)\n",
    "\n",
    "    temp_df = future_predictions[['ds', 'yhat']]\n",
    "    temp_df.rename(columns={'ds': 'Calendar day', 'yhat': 'complaints'}, inplace=True)\n",
    "    \n",
    "    reg_data_future = pd.concat([X_train, X_test, X_val, temp_df], axis=0)\n",
    "\n",
    "    return forecast_val, y_pred_val, future_predictions, temp_df\n",
    "\n",
    "def log_metrics(y_test, y_pred):\n",
    "\n",
    "    def calculate_rmse(predictions, targets):\n",
    "        return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "    \n",
    "    \n",
    "    mse = mean_squared_error(y_true=y_test,\n",
    "                                y_pred=y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test,\n",
    "                                        y_pred=y_pred))\n",
    "    mae = mean_absolute_error(y_true=y_test,\n",
    "                                y_pred=y_pred)\n",
    "\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "    \n",
    "        # Check for input shape compatibility\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError(f\"Input shapes do not match ({y_true.shape}), ({y_pred.shape})\")\n",
    "    \n",
    "        # Calculate absolute percentage error\n",
    "        absolute_error = np.abs((y_true - y_pred) / y_true)\n",
    "    \n",
    "        # Replace infinite values with zero and ignore NaN values\n",
    "        absolute_error = np.nan_to_num(absolute_error, nan=0, posinf=0, neginf=0)\n",
    "    \n",
    "        # Calculate the mean of absolute percentage error\n",
    "        mape = np.mean(absolute_error) * 100\n",
    "    \n",
    "        return mape\n",
    "    \n",
    "    mape = mean_absolute_percentage_error(y_true=y_test, \n",
    "                                            y_pred=y_pred)\n",
    "    smape = np.mean(\n",
    "        2 * np.abs(y_test.values - y_pred) / (np.abs(y_test.values) + np.abs(y_pred))\n",
    "        ) * 100\n",
    "\n",
    "    rmse_seasonal = calculate_rmse(y_pred, y_test.values)\n",
    "\n",
    "    nrmse_seasonal = rmse_seasonal / (np.max(y_test.values) - np.min(y_test.values))\n",
    "    \n",
    "    # # Logging all metrics\n",
    "    mlflow.log_metric('Validation MAE', mae)\n",
    "    mlflow.log_metric('Validation MSE', mse)\n",
    "    mlflow.log_metric('Validation RMSE', rmse)\n",
    "    mlflow.log_metric('Validation MAPE', mape)\n",
    "    mlflow.log_metric('Validation NRMSE', nrmse_seasonal)\n",
    "\n",
    "def log_plots(y_test, y_pred, model, forecast):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    sns.set_style('whitegrid')\n",
    "    ax.plot(y_test['Calendar day'], y_test['complaints'].squeeze(), label='Actual')\n",
    "    ax.fill_between(y_test['Calendar day'], forecast['yhat_lower'], forecast['yhat_upper'], alpha=0.2)\n",
    "    plt.plot(y_test['Calendar day'], forecast['yhat'], label='Predicted')\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.grid(visible=True)\n",
    "    plt.legend()\n",
    "    mlflow.log_figure(fig, 'val_forecasting_result.png')\n",
    "\n",
    "    fig_m = model.plot_components(forecast)\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.legend()\n",
    "    mlflow.log_figure(fig_m, 'val_plot_forecasted_trends_and_components.png')\n",
    "\n",
    "def record_to_blob(df, conn_str: str, container_name: str, secret_client):\n",
    "\n",
    "    conString = secret_client.get_secret(name=conn_str).value\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conString)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob='result.csv')\n",
    "    writer = io.BytesIO()\n",
    "    df.to_csv(writer)\n",
    "    blob_client.upload_blob(writer.getvalue(), overwrite = True)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script\"\"\"\n",
    "\n",
    "    # Input arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data input\n",
    "    parser.add_argument(\"--training_data\", type=str)\n",
    "    parser.add_argument(\"--testing_data\", type=str)\n",
    "    parser.add_argument(\"--validation_data\", type=str)\n",
    "\n",
    "    # Connection input\n",
    "    parser.add_argument(\"--conn_str\", type=str)\n",
    "    parser.add_argument(\"--container_name\", type=str)\n",
    "\n",
    "    # Model input\n",
    "    parser.add_argument(\"--model_prophet\", type=str)\n",
    "\n",
    "    # Forecasting variables\n",
    "    parser.add_argument(\"--periods_horizon\", type=int)\n",
    "    parser.add_argument(\"--freq\", type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Reading data from previous component\n",
    "    X_train = pd.read_csv(select_first_file(args.training_data))\n",
    "    X_test = pd.read_csv(select_first_file(args.testing_data))\n",
    "    X_val = pd.read_csv(select_first_file(args.validation_data))\n",
    "\n",
    "    periods = args.periods_horizon\n",
    "    freq = args.freq\n",
    "\n",
    "    # Loading model\n",
    "    files = [f for f in os.listdir(args.model_prophet) if f.endswith(\".pkl\")]\n",
    "    model = joblib.load(args.model_prophet + \"/\" + files[0])\n",
    "    print(model)\n",
    "\n",
    "    # Making future predictions\n",
    "    forecast_val, y_pred_val, future_predictions, temp_df = model_validate(X_train, X_test, X_val, model, periods=periods, freq=freq)\n",
    "\n",
    "    # Logging metrics\n",
    "    log_metrics(X_val['complaints'].squeeze(), y_pred_val)\n",
    "\n",
    "    # Logging plots\n",
    "    log_plots(X_val, y_pred_val, model, forecast_val)\n",
    "\n",
    "    credential = ManagedIdentityCredential(client_id = open('client_id.txt').readline())  # Client id is an Application ID from Active Directory\n",
    "\n",
    "    secret_client = SecretClient(vault_url='<KEY_VAULT_URL>', credential=credential)  # Secret Client initialization with th access to the desired Key Valut\n",
    "    \n",
    "    record_to_blob(temp_df, args.conn_str, args.container_name, secret_client)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1699969076933
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "demo_prophet_forecast_complaints_component = command(\n",
    "    name=\"demo_prophet_forecast_complaints\",\n",
    "    display_name=\"Demo Prophet forecast for complaints\",\n",
    "    description=\"Component gets the train, test, validation \",\n",
    "    inputs={\n",
    "        \"training_data\": Input(type=\"uri_folder\"),\n",
    "        \"testing_data\": Input(type=\"uri_folder\"),\n",
    "        \"validation_data\": Input(type=\"uri_folder\"),\n",
    "        \"conn_str\": Input(type=\"string\"),\n",
    "        \"container_name\": Input(type=\"string\"),\n",
    "        \"model_prophet\": Input(type=\"uri_folder\"),\n",
    "        \"periods_horizon\": Input(type=\"integer\"),\n",
    "        \"freq\": Input(type=\"string\"),\n",
    "    },\n",
    "    code=forecast_src_dir,\n",
    "    command=\"\"\"python demo_complaints_forecast.py \\\n",
    "            --training_data ${{inputs.training_data}} --testing_data ${{inputs.testing_data}} \\\n",
    "            --validation_data ${{inputs.validation_data}} --model_prophet ${{inputs.model_prophet}} \\\n",
    "            --conn_str ${{inputs.conn_str}} --container_name ${{inputs.container_name}} \\\n",
    "            --periods_horizon ${{inputs.periods_horizon}} --freq ${{inputs.freq}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1699969079026
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mUploading demo_prophet_forecast (0.01 MBs):   0%|          | 0/7105 [00:00<?, ?it/s]\r",
      "\u001b[32mUploading demo_prophet_forecast (0.01 MBs): 100%|██████████| 7105/7105 [00:00<00:00, 77321.43it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component demo_prophet_forecast_complaints with Version 2023-11-14-13-37-58-3703848 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "demo_prophet_forecast_complaints_component = ml_client.create_or_update(\n",
    "    demo_prophet_forecast_complaints_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {demo_prophet_forecast_complaints_component.name} with Version {demo_prophet_forecast_complaints_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Creating pipeline from components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1699969079157
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=cpu_compute_target,\n",
    "    description=\"Complaints forecasting demo\",\n",
    ")\n",
    "def demo_complaints_forecasting(\n",
    "    pipeline_job_sas_token,\n",
    "    pipeline_job_yearly_seasonality,\n",
    "    pipeline_job_seasonality_mode,\n",
    "    pipeline_job_changepoint_prior_scale,\n",
    "    pipeline_job_min_periods,\n",
    "    pipeline_job_freq,\n",
    "    pipeline_job_num_lags,\n",
    "    pipeline_job_column,\n",
    "    pipeline_job_seasonality_prior_scale,\n",
    "    pipeline_job_holidays_prior_scale,\n",
    "    pipeline_job_changepoint_range,\n",
    "    pipeline_job_weekly_seasonality,\n",
    "    pipeline_job_conn_str,\n",
    "    pipeline_job_container_name,\n",
    "    pipeline_job_periods_horizon,\n",
    "    pipeline_job_p,\n",
    "    pipeline_job_d,\n",
    "    pipeline_job_q,\n",
    "    pipeline_job_p_seasonal,\n",
    "    pipeline_job_d_seasonal,\n",
    "    pipeline_job_q_seasonal,\n",
    "    pipeline_job_s,\n",
    "):\n",
    "    # Using model_training_billing_component like a python call with its own input\n",
    "    demo_model_training_billing_job = demo_sales_model_training_component(\n",
    "        sas_token=pipeline_job_sas_token,\n",
    "        p_input=pipeline_job_p,\n",
    "        d_input=pipeline_job_d,\n",
    "        q_input=pipeline_job_q,\n",
    "        p_seasonal_input=pipeline_job_p_seasonal,\n",
    "        d_seasonal_input=pipeline_job_d_seasonal,\n",
    "        q_seasonal_input=pipeline_job_q_seasonal,\n",
    "        s_input=pipeline_job_s,\n",
    "    )\n",
    "\n",
    "    demo_sales_forecast_job = demo_sales_forecast_component(\n",
    "        model_forecast=demo_model_training_billing_job.outputs.model,\n",
    "        df=demo_model_training_billing_job.outputs.df_original,\n",
    "        X_val=demo_model_training_billing_job.outputs.validation_data_sales,\n",
    "    )\n",
    "\n",
    "    demo_feature_creation_job = demo_feature_creation_component(\n",
    "        df=demo_sales_forecast_job.outputs.df_extended,\n",
    "        num_lags=pipeline_job_num_lags,\n",
    "        column=pipeline_job_column,\n",
    "        min_periods=pipeline_job_min_periods,\n",
    "    )\n",
    "\n",
    "    demo_prophet_model_complaints_job = demo_prophet_model_complaints_component(\n",
    "        df_features=demo_feature_creation_job.outputs.df_features,\n",
    "        yearly_seasonality_input=pipeline_job_yearly_seasonality,\n",
    "        seasonality_mode_input=pipeline_job_seasonality_mode,\n",
    "        changepoint_prior_scale_input=pipeline_job_changepoint_prior_scale,\n",
    "        seasonality_prior_scale_input=pipeline_job_seasonality_prior_scale,\n",
    "        holidays_prior_scale_input=pipeline_job_holidays_prior_scale,\n",
    "        changepoint_range_inupt=pipeline_job_changepoint_range,\n",
    "        weekly_seasonality_input=pipeline_job_weekly_seasonality,\n",
    "    )\n",
    "    demo_prophet_forecast_complaints_job = demo_prophet_forecast_complaints_component(\n",
    "        training_data=demo_prophet_model_complaints_job.outputs.training_data,\n",
    "        testing_data=demo_prophet_model_complaints_job.outputs.testing_data,\n",
    "        validation_data=demo_prophet_model_complaints_job.outputs.validation_data,\n",
    "        conn_str=pipeline_job_conn_str,\n",
    "        container_name=pipeline_job_container_name,\n",
    "        model_prophet=demo_prophet_model_complaints_job.outputs.model_prophet,\n",
    "        periods_horizon=pipeline_job_periods_horizon,\n",
    "        freq=pipeline_job_freq,\n",
    "    )\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1699969079334
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "registered_model_name = \"demo_complaints_forecasting\"\n",
    "\n",
    "# Let's instantiate the pipeline with the parameters of our choice\n",
    "pipeline = demo_complaints_forecasting(\n",
    "    pipeline_job_sas_token=\"sas-demo\",\n",
    "    pipeline_job_p=1,\n",
    "    pipeline_job_d=0,\n",
    "    pipeline_job_q=1,\n",
    "    pipeline_job_p_seasonal=3,\n",
    "    pipeline_job_d_seasonal=0,\n",
    "    pipeline_job_q_seasonal=3,\n",
    "    pipeline_job_s=12,\n",
    "    pipeline_job_yearly_seasonality=19,\n",
    "    pipeline_job_seasonality_mode=\"multiplicative\",\n",
    "    pipeline_job_changepoint_prior_scale=2.92877901455971,\n",
    "    pipeline_job_seasonality_prior_scale=6.010013757753535,\n",
    "    pipeline_job_holidays_prior_scale=4.983602164233429,\n",
    "    pipeline_job_changepoint_range=0.809764143539701,\n",
    "    pipeline_job_weekly_seasonality=14,\n",
    "    pipeline_job_min_periods=1,\n",
    "    pipeline_job_freq=\"D\",\n",
    "    pipeline_job_num_lags=3,\n",
    "    pipeline_job_periods_horizon=60,\n",
    "    pipeline_job_column=\"sales\",\n",
    "    pipeline_job_conn_str=\"connection-string-demo\",\n",
    "    pipeline_job_container_name=\"dss-demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1699969084092
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"demo_complaints_forecasting_pipeline\",\n",
    ")\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.studio_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
